\chapter{Set-membership identification}    % For a new chapter (works in book and report class)

Set-membership approach is an alternative to the classical, statistical identification approach. Least-Square method is one possible example of statistical estimation algorithms in the context of estimation.\\
\section{Set-membership identification of single-input-single-output LTI systems}
\subsubsection{Main ingredients}

We consider a discrete-time system described in the following parametrized regression form:\\
\begin{equation}
y(k) = f(y(k-1), y(k-2), \cdots, y(k-n), u(k), u(k-1), \cdots, u(k-m), \theta_1, \theta_2, \cdots, \theta_{n+m+1})
\end{equation}

where \(m\leq n\)\\
A-priori information on the system:
\begin{itemize}
    \item \(n\) and \(m\) are known
    \item \(f \in \mathbb{F}\) where \(\mathbb{F}\) is the class of model selected on the basis of our physical insight. 
\end{itemize}


A-priori information on the noise, the main difference with respect to the previous discussion.
\begin{itemize}
    \item the noise structure is known, i.e. the way the way uncertainty affects the input-output data)
    \item the noise is assumed to belong to konwn bounded set \(\mathbb{B}\).
\end{itemize}

When the consistency property of LS was discussed, and in general statistical approach to system identification, the typicall assumption on the noise is that statistical distribution of the noise sequence, or the value of some moments of inertia of the noise is known, such as variance. Here, the assumption is that the noise sequence \(\eta\) belongs to a bounded \(\mathbb{B}\). Remember that assumption two of the consistency property was the crucial one, so a change of perspective is adopted on the second assumption, where we deal with the following problem:

\textbf{Set-membership identification of LTI system} under the assumption that the uncertainty affecting the data can be modelled as an equation error \(e(k)\), which is exactly assumption \(1\) considered for the consistency theorem.\\
\[
\begin{aligned}
\tilde{y}(k) = & -\theta_1 \tilde{y}(k - 1) - \theta_2 \tilde{y}(k - 2) - \cdots - \tilde{y}(k - n) \\[1ex]
               & + \theta_{n+1} \tilde{u}(k) + \theta_{n+2} \tilde{u}(k - 1) + \cdots + \theta_{n+m+1} \tilde{u}(k - m) + \mathbf{e(k)} \\[2ex]
\end{aligned}
\]
where,
\[
\begin{aligned}
e(k) \in \mathbb{B}e = \left\{ \bar{e} = [e(1), e(2), \cdots, e(H)]^T \right\} : \left| e(k) \right| \leq \Delta e, \forall k
\end{aligned}
\]
where  \(\Delta e \) is a given real bounded constant.

\begin{factbox}[]
In set-membership, we always have unknown and bounded assumption about the magnitude of noise.\\

The bound is considered a conservative bound.

\end{factbox}
\subsubsection{Error-in-Variable setting}
Let's assume that the data are actually collected from a real experiment, which is EIV setup. The block-diagram representation of this a-priori information is as follows.

\begin{center}
\begin{tikzpicture}[auto, node distance=2cm]

    % Block styles
    \tikzstyle{block} = [draw, rectangle, minimum height=2em, minimum width=3em]
    \tikzstyle{sum} = [draw, circle, inner sep=0pt, minimum size=1em]
    \tikzstyle{input} = [coordinate]
    \tikzstyle{output} = [coordinate]

    % Nodes
    \node [input] (input) {};
    \node [sum, right of=input, node distance=2cm] (sum1) {};
    \node [block, right of=sum1, node distance=3cm] (system) {$f(\cdot)$};
    \node [sum, right of=system, node distance=3cm] (sum2) {};
    \node [output, right of=sum2, node distance=2cm] (output) {};

    % Connections
    \draw [->] (input) -- node[pos=0.2] {$u(k)$} (sum1);
    \draw [->] (sum1) -- node[pos=0.8] {$\bar{u}(k)$} (system);
    \draw [->] (system) -- node[pos=0.2] {$y(k)$} (sum2);
    \draw [->] (sum2) -- node[pos=0.8] {$\tilde{y}(k)$} (output);
    
    % Noise terms
    \node [above of=sum1, node distance=1.5cm] (xi) {$\xi(k)$};
    \draw [->] (xi) -- (sum1);
    
    \node [above of=sum2, node distance=1.5cm] (eta) {$\eta(k)$};
    \draw [->] (eta) -- (sum2);

\end{tikzpicture}
\end{center}

\textit{Errors-in-variables} (EIV) problems refer to the most general case where both the input and the output collected samples are affected by noise.

\[
\xi = [\xi(1), \dots, \xi(H)] \in \mathcal{B}_{\xi}
\]
\[
\eta = [\eta(1), \dots, \eta(H)] \in \mathcal{B}_{\eta}
\]

$\mathcal{B}_{\xi}$ and $\mathcal{B}_{\eta}$ are bounded sets described by \textbf{\textit{polynomial constraints}.}

Most common case:
\[
\mathcal{B}_{\eta} = \left\{\eta : |\eta(k)| \leq \Delta_{\eta}\right\}, \quad \mathcal{B}_{\xi} = \left\{\xi : |\xi(k)| \leq \Delta_{\xi}\right\}
\]
Here, $f(.)$ belogn to a class of function $\mathbb{F}$, which is the a-priori assumption on the system.\\

Considering this a-priori information about the structure of the course, and a-priori information about the system, which is LTI second-order system. The noises can be reformulated as \textbf{Error-in-Equation}, which is the same as the first assumption of the consistency property of Least Square.


\[
\begin{array}{l}
\tilde{y}(k)= -\theta_1 \tilde{y}(k - 1) - \theta_2 \tilde{y}(k - 2) + \theta_3 \tilde{u}(k) + \theta_4 \tilde{u}(k - 1) + \theta_5 \tilde{u}(k - 2) \\[1ex]
\textcolor{red}{\fbox{\textcolor{black}{$+ \theta_1\eta(k-1) + \theta_2\eta(k-2) - \theta_3\xi(k) - \theta_4\xi(k-1) - \theta_5\xi(k-2) + \eta(k) $}}} =: + e(k) \\
\end{array}
\]

Up till now, nothing is changes, we now that statistically this kind of error is not i.i.d. The difference in is regarding the second assumption about the noise, \(e(k)\), which is the boundedness of the noise:

\[\left| e(k)\right| \leq \Delta e \forall k = 1, 2, ..., N\]

Provided that we find a way to compute the bound \(\Delta e \), on \(\left| e(k)\right|\), the identification problem can be correctly formulated in terms of \textbf{Equation-Error} structure in Set-membership framework. \textbf{However, Computing \(\Delta e \) is not an easy task}. Since it cannot be done without any assumption about \(\theta_i\), since they are to be identified.

\subsubsection{Set-membership formulation of the problem identifying a second order LTI system assuming an Equation-Error structure for the uncertainty}
Main ingredients:
\begin{enumerate}
\item \textbf{a-priori information }about the system, second order LTI, and the noise, Equation-Error structure and boundedness.
\item\textbf{ a-posteriori information} are experimentally collected input-output data samples.
\end{enumerate}
Now, here, we have the concept of \textit{Feasability Parameter Set}.

\subsubsection{Feasability parameter set}
The feasability parameter set \(\mathbb{D}_\theta\) is the set of all the values of the parameter vector \(\theta = \left[ \theta_1 \theta_2 \cdots \theta_p \right]^T \in \mathbb{R}^p\), which are consistent with all the avialable information on the system and the noise, and all he collected data.\\
To better understand the meaning of FPS, \(\mathbb{D}_\theta\), let's assume that we are collecting data according to the following\textbf{ Output-Error} setup:\\

\begin{center}    % Block styles
\begin{tikzpicture}[auto, node distance=2cm]

    \tikzstyle{block} = [draw, rectangle, minimum height=2em, minimum width=3em]
    \tikzstyle{sum} = [draw, circle, inner sep=0pt, minimum size=1em]
    \tikzstyle{input} = [coordinate]
    \tikzstyle{output} = [coordinate]

    % Nodes
    \node [input] (input) {};
    \node [block, right of=input, node distance=3cm] (system) {$f(\cdot)$};
    \node [sum, right of=system, node distance=3cm] (sum2) {};
    \node [output, right of=sum2, node distance=2cm] (output) {};

    % Connections
    \draw [->] (input) -- node[pos=0.5] {$u(k)$} (system);
    \draw [->] (system) -- node[pos=0.2] {$y(k)$} (sum2);
    \draw [->] (sum2) -- node[pos=0.8] {$\tilde{y}(k)$} (output);
    
    % Noise terms at the output
    \node [above of=sum2, node distance=1.5cm] (eta) {$\eta(k)$};
    \draw [->] (eta) -- (sum2);
\end{tikzpicture}
\end{center}\vspace{1cm}


Since, we have the following form of noise:\\
\[y(k) = \tilde{y} - \eta(k)\]
and we know that \(\eta\) is bounded. we can obtain the following relationship about the \(y(k)\), being that the real \(y(.)\) signal is enveloped in the following fashion:\\
\[
\tilde{y}(k) - \eta{k} \leq y(k) \leq \tilde{y}(k) + \eta{k}
\]

\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.75\textwidth]{images/FPS_time_domain.jpg}
    \caption{The bounds for \(y\) encompass all the elements of the \(\theta\) vector, leading to a relation for \(y\) such that its graph is bounded between the represented bounds.}
    \label{fig:FPS_time_domain}
\end{figure}

\begin{factbox}[Professor's Quotes]
In the statistical identification, assuming probabilistic characteristics for the noise, instead of having bounded interval around each single sample of the output that we collect, we have a normal distribution around each single point. Therefore, a correct formulation of the identification, again, in that context, lead to a set of models, but this time instead of having a bounded set of possible models solving the problem, we obtain a set that is statistically described, where each models have a certain probability of being the correct model.
\end{factbox}

Now, let's try to define mathematically, the FPS \(\mathbb{D}_\theta\)
\[
\begin{aligned}
\mathbb{D}_\theta = \{
\theta = \left[\theta_1 \, \theta_2 \, \cdots \, \theta_p \right]^T \in \mathbb{R}^p \, | \, 
\tilde{y}(k) = & -\theta_1 \tilde{y}(k - 1) - \theta_2 \tilde{y}(k - 2) + \theta_3 \tilde{u}(k) + \theta_4 \tilde{u}(k - 1) \\
& + \theta_5 \tilde{u}(k - 2) + e(k) \, | \, \forall k > 3 \,,\, |e(k)|\leq \Delta e
\}
\end{aligned}
\]
However, this mathematical description is not correct, since here we define FPS as a subset of \textbf{parameter space}, \(\mathbb{R}^p\), but the description of the unknown error is not in the parameter space. How can we reformulate? Although we don't know \(e\), we know that this unknown error is bounded by \(\Delta e\), so how can we exploit this information?

\[
\begin{array}{l}
\mathbb{D}_\theta = \{
\theta \in \mathbb{R}^p \, | \, 
e(k) = \tilde{y}(k) + \theta_1 \tilde{y}(k - 1) + \theta_2 \tilde{y}(k - 2) 
- \theta_3 \tilde{u}(k) - \theta_4 \tilde{u}(k - 1) - \theta_5 \tilde{u}(k - 2), \\
\forall k > 3 \,,\, |e(k)| \leq \Delta e
\}
\end{array}
\]
\[
\Rightarrow
\begin{array}{l}
\mathbb{D}_\theta = \{
\theta \in \mathbb{R}^p \, : \, 
|\tilde{y}(k) + \theta_1 \tilde{y}(k - 1) + \theta_2 \tilde{y}(k - 2) 
- \theta_3 \tilde{u}(k) - \theta_4 \tilde{u}(k - 1) - \theta_5 \tilde{u}(k - 2)|\leq \Delta e, \\ \forall k > 3
\}
\end{array}
\]
Now, we have obtained \textbf{an implicit description} of the set of \textbf{all the feasible solutions to our identification problem}, in terms of a set of inquality constraints only involving \(\theta\). \(\mathbb{D}_\theta\) is now clearly a subset of the parameter space \(\mathbb{R}^p\).

Graphical representation of \(\mathbb{D}_\theta\) in a two-dimensional space case is something of this kind:

\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.65\textwidth]{images/2d-fps.png}
    \caption{a generic two-dimensional FPS}
    \label{fig:2d-fps}
\end{figure}

\subsubsection{Main features of \(\mathbb{D}_\theta\) to be discussed:}


\begin{enumerate}[label=\Roman*.] % Use label=\Roman* for Roman numerals
    \item \textbf{Boundedness of \(\mathbb{D}_\theta\)}
    \item \textbf{Usefulness of \(\mathbb{D}_\theta\)}: What is the relationship between \(\mathbb{D}_\theta\) and \(\theta\), the real value of the parameters.
\end{enumerate}

\textbf{The answer to II: }\\
Assuming that the a-priori assumption about the system and about the noise are correct. then, \(\theta\), the true parameter vector, belong to the set \(\mathbb{D}_\theta\) .

\textbf{The answer to I: }\\
The boundedness of \(\mathbb{D}_\theta\) depends on the way the data is collected. For the moment, let's assume that \(\mathbb{D}_\theta\) is bounded. 

Now that we have obtained an implicit description of \(\mathbb{D}_\theta\), how can a useful model from \(\mathbb{D}_\theta\) can be extracted, e.g. to simulate the behavior of the system under the study or to design a controller for such a system?

We consider two class of SM estimation algorithms, or estimators: 
\begin{enumerate}
\item \textbf{Set-valued estimator:} defined as \textbf{an} estimation algorithm that \textbf{provides a} possibly conservative \textbf{description} of \(\mathbb{D}_\theta\) in \textbf{a simplified geometric form} that can be easily used to simulate or control the system.
\item \textbf{Pointwise estimators:} defined as estimation algorithms that provide a single value of \(\hat{\theta}\), which is an optimal estimate of \(\theta\) \textbf{in some sense to be defined.}
\end{enumerate}

Among all possible estimators in the class \textit{1}, we consider the algorithm that provides the minimum volume box outer bounding \(\mathbb{D}_\theta\).\\

\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.65\textwidth]{images/pui.png}
    \caption{Parameter Uncertainty Intervals, considering the first case mentioned above.}
    \label{fig:PUI}
\end{figure}


This estimator is implicitly providing what we will call \textit{Parameter Uncertainty Intervals}, \textbf{PUI}s defined as bellow: 
\[
PUI_{\theta_J} = \left[\: \underline{\theta_J}, \overline{\theta_J} \: \right]
\]
where: 
\[
\underline{\theta_J} := \min\limits_{\mathbb{D}_\theta} \theta_J
\]
and
\[
\overline{\theta_J} := \max\limits_{\mathbb{D}_\theta} \theta_J = \min\limits_{\mathbb{D}_\theta} (-\theta_J)
\]

Since we know for sure, the true value of the parameter is inside the outerbox, we know that each PUI includes the true value of a parameter.\\

\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.4\textwidth]{images/pui2.png}
    \caption{Parameter Uncertainty Intervals, considering the first case mentioned above.}
    \label{fig:PUI}
\end{figure}
\newpage

\subsubsection{Designing a controller for a system described in this manner}
For instance, consider the following system:\\
\[
G(s) = \frac{\theta_2}{s + \theta_1}
\text{ such that: }
\begin{cases}
\theta_1 \in \left[\underline{\theta_1}, \, \overline{\theta_1} \right] \\
\theta_2 \in \left[\underline{\theta_2}, \, \overline{\theta_2} \right]
\end{cases}
\]
The Bode plot of such a transfer function is a range which can be seen in figure \ref{fig:bode_PUI}.\\

Assuming that you want to design a lead/lag controller in the frequency-domain. We need to consider the Nichol plot which is farthers from -180 and the design procedure is done. In this way after the design, rest assured, all the possible transfer functions would satisfy the requirements.

\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.7\textwidth]{images/bode_PUI.png}
    \caption{The envelop of all a transfer functions described in such a manner with uncertainties on the parameters.}
    \label{fig:bode_PUI}
\end{figure}


\subsubsection{What are the geometrical features of \(\mathbb{D}_theta\) for the specific case when the system is LTI and the uncertanty affects the data can be described by means of a bounded equation error?}
For example, consider the following assumption regarding a-priori information about the system dynamics.
\[
\begin{array}{l}
G(z) = \frac{\theta_2 z}{z + \theta_1} \\ [2ex]
\Rightarrow 
G(q^{-1}) = \frac{\theta_2}{1 + \theta_2 q^{-1}} \\ [2ex]
\Rightarrow 
y(k) = \frac{\theta_2}{1 + \theta_1 q^{-1}} u(k) \\ [2ex]
\Rightarrow 
y(k) + \theta_1 y(k-1) = \theta_2 u(k) \\[2ex]
\Rightarrow
y(k) = -\theta_1y(k-1) +\theta_2 u(k)
\end{array}
\]
A-priori information about the noise is:
\begin{itemize}
    \item Equation Error, \(e(k)\), affects the system.
    \item \(e(k)\) is bounded by a norm, \(|e(k)| < \Delta e\).
\end{itemize}

A-posteriori information are the collected samples of \(\tilde{u}(k), \, \tilde{y}(k)\).\\

Based on the informations at hand:
\[
\begin{array}{c}
\mathbb{D}_\theta = 
\left\{
\theta \in \mathbb{R}^2 : \tilde{y}(k) = - \theta_1\tilde{y}(k-1) + \theta_2 \tilde{u}(k) + e(k), \, |e(k)|<\Delta e \:\: \forall k= 1,2,\cdots,N 
\right\}\\[2ex]
\Rightarrow
\mathbb{D}_\theta = 
\left\{
\theta \in \mathbb{R}^2 : |\tilde{y}(k) + \theta_1\tilde{y}(k-1) - \theta_2 \tilde{u}(k) |<\Delta e \:\: \forall k= 2,\cdots,N 
\right\}\\[2ex]
\Rightarrow
\mathbb{D}_\theta = 
\left\{
\theta \in \mathbb{R}^2 : -\Delta e < \tilde{y}(k) + \theta_1\tilde{y}(k-1) - \theta_2 \tilde{u}(k) ,\:\:  \tilde{y}(k) + \theta_1\tilde{y}(k-1) - \theta_2 \tilde{u}(k) <\Delta e \:\: \forall k>2
\right\}\\[2ex]
\end{array}
\]
Therefore, for \(k=2\) two constraints are obtained on FPS, leading to the regione between two parallel line. 
\[
-\Delta e <\tilde{y}(k) + \theta_1\tilde{y}(k-1) - \theta_2 \tilde{u}(k) \Rightarrow
\theta_2\geq \frac{\tilde{y}(1)}{\tilde{u}(2)} + \frac{\tilde{y}(2) - \Delta e}{\tilde{u}(2)}
\]
Which leads to the following region in the parameter space:\\
THE PLOT TO BE PLOTTED.\\

Here, from the other inequality we obtain the second constraint.\\
\[
\tilde{y}(k) + \theta_1\tilde{y}(k-1) - \theta_2 \tilde{u}(k) <\Delta e \Rightarrow
\theta_2\leq \frac{\tilde{y}(1)}{\tilde{u}(2)} + \frac{\tilde{y}(2) + \Delta e}{\tilde{u}(2)}
\]

THE PLOT TO BE PLOTTED.\\

Exploiting \textit{a-priori} information and two input-output samples, one can obtain an unbounded set for $\mathbb{D}_\theta$. It is evident that, even in the noise-free case, three data samples are needed to solve the system of equations to obtain the true values of the parameters: the order of the system plus the number of parameters. 

For $k = 3$, we obtain two additional constraints, which lead to two parallel lines in the parameter space. This results in a bounded \textbf{Feasible Parameter Set (FPS)} $\mathbb{D}_\theta$. \textbf{Therefore, by our weak assumptions and with three data samples, we have obtained a bounded set as the \textit{Feasible Parameter Set}.}

\begin{factbox}
If the \textit{a-priori} assumptions are correct, the existence of an FPS is guaranteed. However, if the assumptions are not satisfied—either because the system is nonlinear and not LTI, its order is different, or the magnitude of the noise is larger than assumed—the FPS will become a \textbf{null set}. This, in itself, is a positive feature of this method, providing feedback about our estimation. Nonetheless, the statistical method does not enjoy such a property. That is, regardless of the situation, the Least Squares (LS) algorithm will provide an estimation that may not appropriately describe the system.
\end{factbox}

In general, we can conclude that under the considered assumption (LTI system with bounded equation error) the FPS, \(\mathbb{D}_\theta\), is a \textbf{polytope}, and therefore, the PUIs can be numerically computed by solving a set of \textit{linear programming} (LP) problems. \\
\begin{example}[example]
\[
\text{PUI}_{\theta_1} = \left[\underline{\theta_1}, \, \overline{\theta_1}\right]
\]
Considering our LTI system:
\[
\theta_1 = \min\limits_{\theta \in \mathbb{D}_\theta} \theta_1 = \min\limits_{\theta \in \mathbb{R}^n} \theta_1 \text{ subject to }\{ 
\begin{array}{l}
\tilde{y}(k) + \theta_1 \tilde{y}(k-1) - \theta_2 \tilde{u}(k) < \Delta e \\[1ex]
-\tilde{y}(k) - \theta_1 \tilde{y}(k-1) + \theta_2 \tilde{u}(k) < \Delta e
\end{array}\}
\]
In order to obtain the upper bound of \( PUI_{\theta_1} \), it is enough to do minimization for \(-\theta_1\).
\[
\theta_2 = \min\limits_{\theta_1 \in \mathbb{R}^n} -\theta_1 \text{ subject to } \{ 
\begin{array}{l}
\tilde{y}(k) + \theta_1 \tilde{y}(k-1) - \theta_2 \tilde{u}(k) < \Delta e \\[1ex]
-\tilde{y}(k) - \theta_1 \tilde{y}(k-1) + \theta_2 \tilde{u}(k) < \Delta e
\end{array}
\}
\]

\end{example}
A general LP problem is as follows:\\

\[
\min \limits_{x \in \mathbb{R}^n} C^Tx \text{ subject to } Ax\preceq b 
\]

We say that an optimization problem is an LP problem if the problem can be exactly written as the minimization of a linear combination of optimization variable \(x\) subject to a set of linear inequalitiies and/or equalities.\\

LP problems are convex, or at any rate linear, optimization problems that can be solved to the global optimial solution in MATLAB by using the function \textit{\textbf{linprog}}. Therefore, all the time that we have a system with a dynamic that is linear with respect to the parameters, and that we have a bounded noise, we can reach the solve a linear optimization problem.
\begin{QandAbox}
Considering \textbf{the second problem of the first lab}, which asks for the solution of the optimal \(l_\infty\) estimation problem, we consider the same setting used for the first problem, but we look for the following estimation:\\
\[
\hat{\theta}_{l_\infty} = \arg \min\limits_{\theta \in \mathbb{R}^n}\|\bar{y} - A\theta\|_\infty
\]

where \(\|.\|_\infty\) is the \(l_\infty\) norm of a vector.

\textbf{Hint for solving the problem:}\\
\[
\hat{\theta}_{l_\infty} = \arg \max\limits_{\theta \in \mathbb{R}^n}(|\rho(1)|,\, |\rho(2)|,\, \cdots,\, |\rho(N-m)|)
\]
Can this problem be written as an LP problem? the answer is yes and we have to do it to solve the second problem.
\end{QandAbox}

\subsubsection{Set-membership estimation with EIV set-up}
Now, it is aimed to consider a situation which is must more realistic with respect to the previous problem that was dealt with.\\
Previously, we discussed that, even if the noise affects the measurements in the real data acquisition setting in an EIV setting, we can reformulate EIV in an equation error. Nonetheless, we faced a major problem, which is the fact that the error $e(k)$ added to the equation is no more i.i.d.. In set-membership approach being discussed, this is no more a problem as long as it is guaranteed that the norm of this error is going to be bounded; here, there is no assumption on the statistical characteristic of this noise. Now, the problem is that computing a bound for the norm of the error is not an easy task, since after the reformulation of the problem the error norm involve yet-to-be-estimated parameters. Therefore, practically, it is difficult, if not impossible, to compute a bound on the noise, even if the bound of the noise affecting the measurements is known. This is suggesting us that maybe it is better to formulate the problem in another way, not in equation-error, but in EIV setting in a different formulation.

\begin{center}
\begin{tikzpicture}[auto, node distance=2cm]

    % Block styles
    \tikzstyle{block} = [draw, rectangle, minimum height=2em, minimum width=3em]
    \tikzstyle{sum} = [draw, circle, inner sep=0pt, minimum size=1em]
    \tikzstyle{input} = [coordinate]
    \tikzstyle{output} = [coordinate]

    % Nodes
    \node [input] (input) {};
    \node [sum, right of=input, node distance=2cm] (sum1) {};
    \node [block, right of=sum1, node distance=3cm] (system) {$f(\cdot)$};
    \node [sum, right of=system, node distance=3cm] (sum2) {};
    \node [output, right of=sum2, node distance=2cm] (output) {};

    % Connections
    \draw [->] (input) -- node[pos=0.2] {$u(k)$} (sum1);
    \draw [->] (sum1) -- node[pos=0.8] {$\bar{u}(k)$} (system);
    \draw [->] (system) -- node[pos=0.2] {$y(k)$} (sum2);
    \draw [->] (sum2) -- node[pos=0.8] {$\tilde{y}(k)$} (output);
    
    % Noise terms
    \node [above of=sum1, node distance=1.5cm] (xi) {$\xi(k)$};
    \draw [->] (xi) -- (sum1);
    
    \node [above of=sum2, node distance=1.5cm] (eta) {$\eta(k)$};
    \draw [->] (eta) -- (sum2);

\end{tikzpicture}
\end{center}

\textit{Errors-in-variables} (EIV) problems refer to the most general case where both the input and the output collected samples are affected by noise.

\[
\xi = [\xi(1), \dots, \xi(H)] \in \mathcal{B}_{\xi}
\]
\[
\eta = [\eta(1), \dots, \eta(H)] \in \mathcal{B}_{\eta}
\]

$\mathcal{B}_{\xi}$ and $\mathcal{B}_{\eta}$ are bounded sets described by \textbf{\textit{polynomial constraints}.}

Most common case:
\[
\mathcal{B}_{\eta} = \left\{\eta : |\eta(k)| \leq \Delta_{\eta}\right\}, \quad \mathcal{B}_{\xi} = \left\{\xi : |\xi(k)| \leq \Delta_{\xi}\right\}
\]
which is a hyper-dimensional box.

A subset of this problem, as was discussed also in the previous chapter, is Output-Error, OE, set-up, meaning that the input signal is perfectly known.


\begin{center}    % Block styles
\begin{tikzpicture}[auto, node distance=2cm]

    \tikzstyle{block} = [draw, rectangle, minimum height=2em, minimum width=3em]
    \tikzstyle{sum} = [draw, circle, inner sep=0pt, minimum size=1em]
    \tikzstyle{input} = [coordinate]
    \tikzstyle{output} = [coordinate]

    % Nodes
    \node [input] (input) {};
    \node [block, right of=input, node distance=3cm] (system) {$f(\cdot)$};
    \node [sum, right of=system, node distance=3cm] (sum2) {};
    \node [output, right of=sum2, node distance=2cm] (output) {};

    % Connections
    \draw [->] (input) -- node[pos=0.5] {$u(k)$} (system);
    \draw [->] (system) -- node[pos=0.2] {$y(k)$} (sum2);
    \draw [->] (sum2) -- node[pos=0.8] {$\tilde{y}(k)$} (output);
    
    % Noise terms at the output
    \node [above of=sum2, node distance=1.5cm] (eta) {$\eta(k)$};
    \draw [->] (eta) -- (sum2);
\end{tikzpicture}
\end{center}\vspace{1cm}
where,
\begin{itemize}
\item 
\[
\eta = \left[\eta(1),\,\eta(2),\, \cdots,\,\eta(H)\right] \in \mathbb{B}_\eta
\]
\item \(\mathbb{B}_\eta\) is a bounded set described by \textbf{\textit{polynomial constraints}}.
\item Most common case: \(\mathbb{B}_\eta = \left\{\eta: \: |\eta(k)| \leq \Delta_\eta \right\}\)
\end{itemize}

The FPS for the general EIV problem is implicitly defined as follows:
\[
\begin{array}{c}
\mathbb{D}_\theta = \{ \theta \in \mathbb{R}^n : \, y(k) = f( y(k-1), y(k-2), \cdots, y(k-n),  u(k), u(k-1), \cdots \\[1ex]
, u(k-m), \theta_1, \theta_2, \cdots, \theta_{n+m+1}),k = n+1,\,n+2,\,\cdots,\,N,\: y(k) = \tilde{y}(k) - \eta(k), \\[1ex]
u(k) = \tilde{u}(k) - \xi(k),\: k=1,\,2,\,\cdots,\,N,\: |\xi(k)|\leq \Delta\xi(k),\: |\eta(k)\leq \Delta\eta(k),\: k = 1,\,2,\,\cdots,\,N \}
\end{array}
\]

The FPS for the case of \textbf{LTI descrete-time systems with EIV noise structure} is given by:
\[
\mathbb{D}_\theta = \left\{ \theta \in \mathbb{R}^p : \, (\tilde{y}(k) - \eta(k)) + \sum_{i=1}^{n} a_i (\tilde{y}(k - i) - \eta(k - i)) = \sum_{j=0}^{m} b_j (\tilde{u}(k - j) - \xi(k - j)), \right.
\]
\[
\left. t = n + 1, \dots, H, \quad |\xi(k)| \leq \Delta\xi(k), \quad |\eta(k)| \leq \Delta\eta(k), \quad k = 1, \dots, H \right\}
\]
This includes \(2N\) new variables involved in the FPS which are not variables in parameter space. Now, these variables should be eliminated, and this is not possible without setting some conservative conditions. \textbf{If you come up with an idea to do so without considering conservative conditions, you can publish a paper}. 

Since the FPS defined in the above equation depends on some additional unknownes( all the samples of the noise sequences). The constraints defining \(\mathbb{D}_\theta\) cannot be rearranged in such a way to eliminate dependancies on such additional variables. To solve the problem, we need to extend the space of decision variables in by defining the \textit{Extended Feasible Parameter Set}(EFPS).

\[
\begin{array}{c}
\mathcal{D}_{\theta,\eta,\xi} = \left\{ \theta \in \mathbb{R}^p, \eta \in \mathbb{R}^H, \xi \in \mathbb{R}^H : \right.
(y(k) - \eta(k) + \sum_{i=1}^{n} a_i ( y(k-i) - \eta(k-i)) = \\[2ex]
\sum_{j=0}^{m} b_j ( u(k-j) - \xi(k-j) ), \, t = n+1,\dots,H, \\[2ex]
|\xi(k)| \leq \Delta \xi(k), \, |\eta(k)| \leq \Delta \eta(k), \, k = 1,\dots,H \left.\right\}
\end{array}
\]
As you can see in the box below, here, we are expanding the space we are considering for FPS, hence EFPS.
\begin{align}
\fcolorbox{red}{white}{$\mathcal{D}_{\theta,\eta,\xi} = \left\{ \theta \in \mathbb{R}^p, \eta \in \mathbb{R}^H, \xi \in \mathbb{R}^H\right\}$}
\end{align}
A simplified graphical version is shown in the following graph. \textbf{Now, the FPS is the projection of the EFPS on the parameter space}.

\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.7\textwidth]{images/EFPS.png}
    \caption{A simplified, general graph of EFPS.}
    \label{fig:EFPS}
\end{figure}

In this case,
\[
\underline{\theta}_k = \min\limits_{\theta \in \mathbb{D}_\theta} \theta_k = \min\limits_{\theta, \eta, \xi \in \mathbb{D}_{\theta, \eta, \xi}} \theta_k
\]
That is,
\[
\begin{array}{rcl}
\theta_k & = & \min_{\theta \in \mathbb{D}_{\theta, \eta, \xi}} \theta_k \text{ subject to } \tilde{y}(k) - \eta(k) + \sum_{i=1}^{n} \theta_i(\tilde{y}(k-i) - \eta(k-i)) \\[1ex]
& & + \theta_{n+1}(\tilde{u}(k) - \xi(k)) + \sum_{j=1}^{m} \theta_{n+j+1}(\tilde{y}(k-j) - \xi(k-j)), \\[1ex]
& & \quad \forall k > n+1, \, |\xi(k)| \leq \Delta \xi, \, |\eta(k)| \leq \Delta \eta, \, \forall k
\end{array}
\]

The drawback is that EFPS is a non-convex set defined by \textbf{polynomial} (\textit{bilinear}) constraints.

\begin{factbox}[Professor's Quote:]
To the best of my knowledge, in the domain of non-convex functions, the only class that can be optimized up to the global minimum is the class of non-convex functions with polynomial constraints.
\end{factbox}

\begin{QandAbox}[Boundedness of the noise]
Practically, the assumption that the noise can take any value is unreasonable. Since sensors are used for measurements and are designed to be stable and precise, it is not realistic for the noise to take on any value. For this reason, it makes sense to assume bounded noise.
\end{QandAbox}

\begin{factbox}[What signal to use as input signal?]
If the signal applied to a system is simply a \textbf{ramp} or \textbf{step} signal, after the transient period, the output will reflect the generalized DC gain of the system when it reaches steady-state. Therefore, a staircase of steps with varying amplitudes combined with a random signal may be a good choice to stimulate different modes of the system.
\end{factbox}

Refer to Lab 01, Problem 2, for least squares with \( l_\infty \)-norm.

Consider the following FPS. Due to its non-convexity, the optimizer may return a local minimum, which is not desirable.

\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.7\textwidth]{images/non-convex-FPS.png}
    \caption{A simplified, general graph of EFPS.}
    \label{fig:non-convex-FPS}
\end{figure}



\subsubsection{Convext relaxation for polynomial optimization problem}
General ideas and intuitions are as follows: \\
let's consider the following general polynomial optimizatin problem:
\[
\min\limits_{x} f_0(x) \text{ s.t. } 
\begin{cases}
f_k(x) \leq 0\: (k\,=\,1,\,2,\, \cdots,\, l)\\
f_k(x) = 0\: (k\,=\,l+1,\,l+2,1,\cdots,\, m)
\end{cases}
\]
where, $f_0$ and $f_k$ are multivariable polynomials in the optimization variables$x$.

\begin{example}[Example 1]
\(
x =
\begin{bmatrix}
    x_1 \\
    x_2 \\
    x_3
\end{bmatrix}
\)\\ \\
The following is what we call \textit{Polynomial Optimization Problem} \textbf{POP}\\
\(
\min (x_1^2 + x_2x_3^3 + x_1^5x_2^3 + 7x_3^2 + \cdots)
\)\\ \\
for the second order case:
\(
f_0(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \theta_3x_1x_3 + \theta_4x_1^2 + \theta_5x_2^2
\)\\ \\
\end{example}

\begin{example}[Example 2]
a constraint POP
\(
\min (x_1^2 + 11x_2) \text{ s. t. } 
\begin{cases}
x_1^2 - 4 = 0 \\
x_1^3 + 7x_2 - 13x_1x_2 \leq 0
\end{cases}
\)\\ \\
\end{example}

All POPs can be written in the so-called \textit{epographic} form by introducing a new "slack" variable $\gamma$.
\[
\begin{array}{ll}
    \min\limits_{x} & f_0(x) \\
    \text{s.t.} & \\
      &\\
    & f_1(x) \geq 0 \\
    & f_2(x) \geq 0 \\
    & \vdots \\
    & f_5(x) \geq 0 \\
    & f_k(x) = 0 \\
  
\end{array}
\quad \Longleftrightarrow \quad
\begin{array}{ll}
    \min\limits_{x,\,t}t &  \\
    \text{s.t.} & \\
    & f_0(x) \leq t \text{  or  } t - f_0(x) \leq 0 \\
    & f_1(x) \geq 0 \\
    & f_2(x) \geq 0 \\
    & \vdots \\
    & f_5(x) \geq 0 \\
    & f_k(x) = 0 \\
\end{array}
\]

By rewriting a generic POP in the epigraphic form, we recognize that a generic POP can be seen as the problem of minimizing a linear function over a non-convex set described by polynomial constraints. This is also true for unconstraint POP.

\[
\begin{array}{ll}
    \min\limits_{x} & f_0(x) \\
      &\\
      &\\
\end{array}
\quad \Longleftrightarrow \quad
\begin{array}{ll}
    \min\limits_{x,\,t} & t \\
    \text{s.t.} & \\
     t - f_0(x) \leq 0 \\
  
\end{array}
\]

A graphical representation of this problem is as follows:

\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.7\textwidth]{images/epigraphic-mini.png}
    \caption{the geraphical representation of a generic epigraphic minization, each line represent different values of t.}
    \label{fig:non-convex-FPS}
\end{figure}

\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.65\textwidth]{images/linprog.png}
    \caption{Graphical representation of a linear programming over $\theta_1$}
    \label{fig:non-convex-FPS}
\end{figure}
\begin{QandAbox}[Important Remark]
Since a generic POP can be rewritten in the epigraphic form that is the problem of minimizing a linear function over a non-convex set, the non-convexity of the problem is now completely embedded in the description of the set of constraint.
\end{QandAbox}

If we want to be able to compute the global optimal solution to the non-convex POP, we have to deal with the non-convexity of the set of constraints.

Now, the idea is to replace the non-convex set with a convex set such that the result of the global optima is equal to that of non-convex.

\subsubsection{Convex-hull of a non-convex set}
The convex-hull of a non-convex set $S$ is
the smallest convex set that is including $S$.


\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.65\textwidth]{images/convex-hull.png}
    \caption{convex-hull of a generic non-convex set}
    \label{fig:non-convex-FPS}
\end{figure}

The general idea here is that if we are able to write down equation describing convex-hull $C_S$ of the non-convex set $S$:
\[
\min\limits_{x \in C_s} f(x) = \min\limits_{x \in S} f(x)
\]
where $f(x)$ is a linear function of $x$.

However, in general, computing the mathematical description of the convex haul is quite a difficult problem. For the case of POPS - a particular class of non-convex optimization problem - Lassere et al were able to compute \textbf{a convex relaxation} of $S$ depending on a parameter which is called \textbf{\textit{order of relaxation $\delta$}}.

For a given fixed value of $\delta$ we have the following situation. For different order of relaxation, we obtain different convex sets including the original set. They proved by increasing the order of relaxation, we obtain convex sets that is the convex set of the original set. For the problems we are dealing with, the optimal solution is obtained with a fixed value of relaxation, and convergence is typically really fast. The issue is that the value of the $\delta$ is not known.

\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.65\textwidth]{images/convex-relaxation.png}
    \caption{convex-hull of a generic non-convex set}
    \label{fig:non-convex-FPS}
\end{figure}

\begin{itemize}
    \item Computation of parameter bounds (PUIs) require the solution to the global optimum of non-convex polynomial optimization problems.
    
    \item By applying \textit{Moments theory} (Lasserre) or \textit{Sum-of-squares (SOS) theory} (Chesi, Parrilo), it is possible to build a sequence of \textbf{convex} semidefinite (SDP) optimization problems whose size/complexity depends on a parameter called \textit{order of relaxation} \(\delta\).
    
    \item For any given \(\delta\), the following inequalities hold
    \[
    \theta^{\delta}_k \leq \theta_k, \quad \overline{\theta}^{\delta}_k \geq \overline{\theta}_k 
    \]
    
    \item Furthermore,
    \[
    \lim_{\delta \to \infty} \theta^{\delta}_k = \theta_k, \quad \lim_{\delta \to \infty} \overline{\theta}^{\delta}_k = \overline{\theta}_k
    \]
\end{itemize}

In gradient-based algorithms, we have the risk of underestimating the value of the parameters by trapping into local minima, while in this method, rest assured, the true value of the parameters is going to be included in the interval.

In order to solve POPs by means of Lassere convex-relaxation appraoch in MATLAB, we use the following two software, which are MATLAB toolboxes, that can be freely downloaded online:
\begin{itemize}
\item SparsePOP: given a POP and a value of the order of relaxation $\delta$, provides\textbf{ the SDP relaxed problem.}
\item Sedumi: is called by SparsePOP to solve the obtained convex SDP.
\end{itemize}

\subsubsection{The lecture after the lab 03}
In the laboratory, we saw that SparsePOP computes convex relaxation for a given relaxation. The Sediumi toolbox is used to solve the relaxed optimization problem.\\

\subsubsection{Selection of the order of relaxation}
Let's call $x^*$ the global optimal solution of a given POP, and $x^*$ the solution of the corresponding convex relaxation of order $\delta$.\\

QUESTION: How to selcet $\delta$?\\
Well, from the theory we have the following results:\\
\textbf{R1)} 
\[
\lim\limits_{\delta \to \infty} f(x^\delta) = f(x^*)
\]
which implies, the following, to be unprecise:
\[
\lim\limits_{\delta \to \infty} = x^*
\]

\textbf{R2)}: \(\delta) \geq \lceil \frac{n_{max}}{2} \rceil\), where $n_{max}$ is the maximum degree of the polynomial describing the functional and the constraints.\\

\textbf{R3)} the complexity of SDP problem obtained by applying to the original convex relaxation techniques grows exponentially in the order of relaxatoin $\delta$, as well as the number of optimization variables (AKA decision variables) of the original POP.\\

On the other hand, we have the following result too:\\

\textbf{R4)}: For a large class of problems including most of the problems in this course, it is possible to prove that the convergence to the global optimal solution of the original POP is very fast and it is achieved for a finite value of $\delta$. but still the result number 2 should be satisfied.\\

Let's analyze the impact of R1, R2, R3, and R4 on the applicationo of convex relaxation techniques to a set-membership identification problem of an LTI system with EIV assuption about the noise.\\

For SM Id. of LTI system with EIV of a polynomial of order 2, we can start with $\delta =1$. Because we have bi-linear constraints, i.e. polynomial constraints of order 2. Number of optimization variable is given by:
\[
P + 2N
\]
Where $P$ is the number of parameters to be identified and $N$ is the number of pair of data samples. Since in system identification problem $N$ is going to be quite large in many applications in order to obtain accurate PUI's, the complexity is going to be untractable. Nonetheless, the following result can be exploited:\\
\textbf{R5)} if the structure of the original POP satisfies a property called \textit{running intersection property}, it's possible to build a sequency of convex SDP relaxation, involving much less variables. (Sparse Convex - relaxation)

\begin{factbox}[about SparsePOP]
SparsePOP toolbox is able to automatically check whether the original POP satisfies the running intersection property, and if this is the case,
it applies the \textit{sparse convex relaxation}.
\end{factbox}

\textbf{R6)} The complexity of SDP problem obtained by applying the sparse convex relaxation to the original POP:
\begin{itemize}
\item\textbf{grows exponentially iwth the order of relaxation}.
\item \textbf{grows linearly with the number of optimization variables}.
\end{itemize}

\textbf{R6} tell us that the SM - ID problem for LTI system with EIV assumption is computationally tractable for a rather large value of input-output pair of experimentally collected data ($N$), since the problem satisfies the \textbf{running intersection property} and it is characterized by \textbf{bilinear constraints}, which allow us to start with relaxation $\delta =1$.

\begin{QandAbox}
considering that the problem is computationally tracktable having the constraints are bilinear. can we find a trick to solve a polynomial with large number of parameters, which may be computationally untracktable?
\end{QandAbox}

\subsubsection{How to formulate the SM - ID problem for an LTI system of order $n$ with EIV noise structrue, in terms of SparsePOP}:\\
\begin{QandAbox}[Exam matter]
The following procedure is what should be done to solve the exam problem.
\end{QandAbox}
\begin{enumerate}
\item First, let's write down the FPS and the EFPS. To simplify, here, we consider $n = 2$.\\
FPS:
\[
\begin{array}{c}
\mathbb{D}_\theta = \{\theta \in \mathbb{R}^5: y(k) + \theta_1 y(k-1) + \theta_2 y(k-2) - \theta_3 u(k) -\theta_4 u(k-1) -\theta_5 u(k-2) = 0 \\
\forall k = 3,\,4,\,\cdots,\,N, |\eta(k)\leq\Delta\eta, |\xi(k)|\leq \Delta\xi, \forall k \in \mathbb{N} 
\}
\end{array}
\]
EFPS:
\[
\begin{array}{l}
\mathbb{D}_{\theta,\,\eta,\,\xi}= \{\theta \in \mathbb{R}^5,\, \eta \in \mathbb{R}^N,\,\mathbb{R}^N
: 
\tilde{y}(k) - \eta(k)+ \theta_1 \tilde{y}(k-1) - \theta_1\eta(k-1) + \theta_2 \tilde{y}(k-2)\\-\theta_2\eta(k-2) - \theta_3 \tilde{u}(k) + \theta_3\xi(k) -\theta_4 \tilde{u}(k-1) + \theta_4\xi(k-1) -\theta_5 \tilde{u}(k-2) + \theta_5\xi(k-2) = 0 \\
\forall k = 3,\,4,\,\cdots,\,N,
|\eta(k)|\leq\Delta\eta, |\xi(k)|\leq \Delta\xi, \forall k \in \mathbb{N} 
\}
\end{array}
\]

PUI:
\[
PUI_k = \left[\underline{\theta}_k,\,\overline{\theta}_k \right]
\]
where
\[
\begin{array}{c}
\underline{\theta}_k = \min\limits_{\theta \in \mathbb{D}_\theta} \theta_k = \min\limits_{\theta, \eta, \xi \in \mathbb{D}_{\theta, \eta, \xi}} \theta_k \quad \text{s.t.} \\
\tilde{y}(k) - \eta(k) + \theta_1 \tilde{y}(k-1) - \theta_1\eta(k-1) + \theta_2 \tilde{y}(k-2) - \theta_2\eta(k-2) \\
- \theta_3 \tilde{u}(k) +\theta_3 \xi(k) - \theta_4 \tilde{u}(k-1) + \theta_4\xi(k-1) - \theta_5 \tilde{u}(k-2) + \theta_5 \xi(k-2) = 0 \quad \forall k = 3,\,4,\,\cdots,\,N,\\
\eta(k) + \Delta\eta \geq 0, \quad \Delta\eta - \eta(k) \geq 0, \quad \xi(k) + \Delta\xi \geq 0, \quad \Delta\xi - \xi(k) \geq 0 \quad \forall k \in \mathbb{N} 
\end{array}
\]

\[
\begin{array}{c}
\overline{\theta}_k = \max\limits_{\theta \in \mathbb{D}_\theta} \theta_k = \max\limits_{\theta, \eta, \xi \in \mathbb{D}_{\theta, \eta, \xi}} \theta_k \quad \text{s.t.} \\
\tilde{y}(k) - \eta(k) + \theta_1 \tilde{y}(k-1) - \theta_1\eta(k-1) + \theta_2 \tilde{y}(k-2) - \theta_2\eta(k-2) \\
- \theta_3 \tilde{u}(k) +\theta_3 \xi(k) - \theta_4 \tilde{u}(k-1) + \theta_4\xi(k-1) - \theta_5 \tilde{u}(k-2) + \theta_5 \xi(k-2) = 0 \quad \forall k = 3,\,4,\,\cdots,\,N,\\
\eta(k) + \Delta\eta \geq 0, \quad \Delta\eta - \eta(k) \geq 0, \quad \xi(k) + \Delta\xi \geq 0, \quad \Delta\xi - \xi(k) \geq 0 \quad \forall k \in \mathbb{N} 
\end{array}
\]
\item Formulating the obtained POP in terms of SparsePOP data structure.\\
Let's consider how to describe in SparsePOP terms the bilinear eqaulity constraints. Considering k = 3.
\[
\tilde{y}(3) - \eta(3) + \theta_1 \tilde{y}(2) - \eta(2) + \theta_2 \tilde{y}(1) - \eta(1) \\
- \theta_3 \tilde{u}(3) + \xi(3) - \theta_4 \tilde{u}(2) + \xi(2) - \theta_5 \tilde{u}(1) + \xi(1) = 0
\]
Now, we have to shape our data structure for this inequality.
\begin{example}
\begin{lstlisting}
ineqPolySys{c}.typeCone = -1; equality constraint
ineqPolySys{c}.dimVar = 5 + 2*N; 
% P: the number of variables involved, P = 5
% N: the number of pairs of input-output data samples
ineqPolySys{c}.degree = 2; %always 2,for bilinear equations
ineqPolySys{c}.noTerms = 12;
ineqPolySys{c}.supports = sup_matrix;
ineqPolySys{c}.coef = [y_tilde(3);-1;y_tilde(2);-1; ...]';
\end{lstlisting}
\end{example}
Support matrix show have as many row as the terms in the constraints and as many constraints as the number of optimization variables $P + 2*N$.
\newpage
\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.75\textwidth]{images/support-matrix1.png}
    \caption{Support matrix for the equality constraints}
    \label{fig:non-convex-FPS}
\end{figure}
\end{enumerate}

Regarding the constraints on the boundedness of the noise, they can be imposed consider a lower bound and upper bound for the variables corresponding to the noise. Look at the solution of lab 03.

\newpage

\section{Set-membership identification of multi-input-multi-output LTI system}
Now that we have considered SISO LTI system, a new direction can be considering MIMO systems. Again, to formulate our problem, we should consider our a-priori and a-posteriori informations.

\subsubsection{A-priori information on the system}
The system is a MIMO LTI system with $p$ input and $q$ outputs, described by means of a \textbf{matrix transfer function} $G(q{-1})$, where the elements of it are SISO transfer function.


\[
\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_q
\end{bmatrix}
=
\begin{bmatrix}
G_{11}(q^{-1}) & G_{12}(q^{-1}) & \dots & G_{1p}(q^{-1}) \\
G_{21}(q^{-1}) & G_{22}(q^{-1}) & \dots & G_{2p}(q^{-1}) \\
\vdots         & \vdots         & \ddots & \vdots         \\
G_{q1}(q^{-1}) & G_{q2}(q^{-1}) & \dots & G_{qp}(q^{-1})
\end{bmatrix}
\begin{bmatrix}
u_1 \\
u_2 \\
\vdots \\
u_p
\end{bmatrix}
\]

\begin{factbox}[Discussion about the structure this matrix transfer function]
In general, The denuminator of these transfer functions can be different, but considering that the transfer function can be obtained from steady-state representation of the system, $C*(sI-A)^{-1}B + D$, before the possible cancellations, The denuminator of all of these transfer functions would be the same. Having this consideration, less parameters should be identified. On the otherhand, in this case, the possible cancellations are hard to be recognized, due to the range obtained for each zero, PUI. In another possible case, some a-priori information regarding the degree of the transfer functions might be available. In that, we know that the order of a given output with respect to a given input is going to be of a specific value. 
\end{factbox}

The generic output $y_i$ is given by:
\[
y_i = G_{i1}(q^{-1}) + G_{i1}(q^{-1}) + \cdots + G_{i1}(q^{-1}) \:\:\forall\:\: i = 1,\,2,\,\cdots,\,q
\]
where each output $y_i$ only depends on the past samples of the output itself and the samples of the inputs $u_1,\,u_2,\,\cdots,\,u_p$. Identification of a \textbf{MIMO LTI} system with $q$ outputs is equivalent to the identification of $q$ \textbf{MISO LTI systems}.

Therefore, we can focus on the problem of set-membership identification of MISO LTI systems.

\subsubsection{Set-membership identification of LTI MISO with $p$ inputs}
\textbf{A-priori information about the system:}
\[
y = G
\begin{bmatrix}
u_1 \\
u_2 \\
\vdots \\
u_p
\end{bmatrix}
\]
where
\[
G = [G_{1},\, G_{2},\,\dots,\, G_{p}]
\]
and in turn,
\[
G_i(q^{-1}) = \frac{\beta_{0i} +\beta_{1i}q^{-1} + \cdots + \beta_{pi}q^{-ni}}{1+\alpha_{1i}q^{-1} + \cdots + \alpha_{qi}q^{-ni}}
\]
here, $ni$, is the dynamical order of $G_i$.

\textbf{A-priori information about the noise:}\\
We assume an EIV structure for the noise affecting the data; that is,

\begin{figure}[htbp]  % "h" for here, "t" for top, "b" for bottom, "p" for float page
    \centering
    \includegraphics[width=0.85\textwidth]{images/MISO.jpg}
    \caption{The scheme of the error entering the system in an EIV setting.}
    \label{fig:MISO}
\end{figure}

A-posteriori information: N samples of the inputs and the output sequences experimentaly collected. \\
Let's define the feasible parameter set:
\[
\mathcal{D}_a = \left\{ \theta \in \mathbb{R}^{\sum_{k=1}^{2n+1}} : 
\begin{array}{l}
y = G_1 u_1 + G_2 u_2 + \cdots + G_p u_p, \\
y = \tilde{y} + \eta, \\
u_1 = \tilde{u}_1 + \xi_1, \, \cdots, \, u_p = \tilde{u}_p + \xi_p, \\
|\xi_1| \leq \Delta \xi_1, \, \cdots, \, |\xi_p| \leq \Delta \xi_p, \, |\eta| \leq \Delta \eta, \, \forall k \in \mathbb{N}
\end{array}
\right\}
\]
So,
\[
\mathcal{D}_a = \left\{ \theta \in \mathbb{R}^{\sum_{k=1}^{2n+1}} : 
\begin{array}{l}
y = \frac{\beta_0^1 + \beta_1^1 q^{-1} + \beta_2^1 q^{-2} + \cdots + \beta_n^1 q^{-n}}{1 + \alpha_1^1 q^{-1} + \alpha_2^1 q^{-2} + \cdots + \alpha_n^1 q^{-n}} u_1 + \cdots \\[2em]\]+ \frac{\beta_0^p + \beta_1^p q^{-1} + \beta_2^p q^{-2} + \cdots + \beta_n^p q^{-n}}{1 + \alpha_1^p q^{-1} + \alpha_2^p q^{-2} + \cdots + \alpha_n^p q^{-n}} u_p, \\
y = \tilde{y} + \eta, \\
u_1 = \tilde{u}_1 + \xi_1, \, \cdots, \, u_p = \tilde{u}_p + \xi_p, \\
|\xi_1| \leq \Delta \xi_1, \, \cdots, \, |\xi_p| \leq \Delta \xi_p, \, |\eta| \leq \Delta \eta, \, \forall k \in \mathbb{N}
\end{array}
\right\}
\]

How to solve this problem? Mathematically, output is the superposition of the inputs, it might be time consuming, but we can identify single $G_i$'s. In real world problems, nothing is Linear, so different inputs affect the linearity of the system, so MISO problems cannot be written as SISO problems. Now, we should find a solution for our problem.
